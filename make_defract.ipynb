{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6ceae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for importing, formatting and data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6418c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import your ASV biom table\n",
    "bac_biom = pd.read_csv('ASVs_bact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24533e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_defract(all_md, separated):\n",
    "\n",
    "    #make sure all size codes are indicated\n",
    "    all_md[\"size_code\"] = all_md[\"sampleid\"].str.extract(r'[1-9][0-9]?[A-E]([L-S])')\n",
    "    all_md[\"size_code\"] = all_md[\"size_code\"].fillna('W')\n",
    "\n",
    "    #only keep values from weeks 1 to 16\n",
    "    sep_SL = all_md[all_md.size_code != \"W\"]\n",
    "    sep_SL = all_md[all_md.size_code != \"P\"]\n",
    "    sep_SL = sep_SL.drop(sep_SL[sep_SL.weekn > 16].index)\n",
    "\n",
    "    #sum [DNA] of small and large size fractions\n",
    "    sep_SL['[DNAt]'] = sep_SL.groupby(['weekn', 'depth'])['[DNA]ng/ul'].transform('sum')\n",
    "\n",
    "    #separate small and large size fraction\n",
    "    sep_S = sep_SL[sep_SL.size_code == 'S']\n",
    "    sep_L = sep_SL[sep_SL.size_code == 'L']\n",
    "\n",
    "    #calculate DNA proportion per size fraction\n",
    "    sep_SL['DNApr'] = sep_SL['[DNA]ng/ul']/sep_SL['[DNAt]']\n",
    "\n",
    "    #merge with separated on common columns to get corresponding rel. abundances\n",
    "    sep_SL = sep_SL[['sampleid', 'DNApr', '[DNAt]']].copy()\n",
    "    sepSLRA = pd.merge(separated, sep_SL, on=['sampleid'], how='left') #all_md is the metadata file\n",
    "\n",
    "    #exclude ASVs from the whole water\n",
    "    sep_SLRA = sepSLRA[separated.size_code != \"W\"]\n",
    "    sep_SLRA = sepSLRA[separated.size_code != \"P\"]\n",
    "\n",
    "    #calculate corrected per sample ratio, and corrected feature frequency of de-fractionated samples\n",
    "    sep_SLRA['Newfeature_frequency'] = sep_SLRA['feature_frequency'] * sep_SLRA['DNApr']\n",
    "    sep_SLRA['Newff'] = sep_SLRA.groupby(['feature_id', 'weekn', 'depth'])['Newfeature_frequency'].transform('sum')\n",
    "\n",
    "\n",
    "    #sep_SLRA = sep_SLRA.drop(['sampleid', 'size_code'], axis=1)\n",
    "    sep_SLRA['sampleid'] = \"BB22.\" + sep_SLRA['weekn'].astype(str) + sep_SLRA['depth_code'] + \"SL\"\n",
    "\n",
    "    #uncomment the line below if keeping small and large original sample\n",
    "    #sep_SLRA['size_code'] = sep_SLRA['size_code'] + '-DFr'\n",
    "\n",
    "    #uncomment the line above if merging smallandlarge\n",
    "    sep_SLRA['size_code'] = 'SL'\n",
    "\n",
    "    #drop unecessary columns which might rise merging conflicts\n",
    "    sep_SLRA = sep_SLRA.drop(['feature_frequency', 'Total', 'ratio', 'nASVs', 'weekdepth', 'avg',\n",
    "                              'diff', 'extraction_date', '[DNA]ng/ul', 'A260/280', 'A260/230',\n",
    "                              'Newfeature_frequency'], axis=1)\n",
    "    sep_SLRA.rename(columns={'Newff':'feature_frequency'}, inplace=True)\n",
    "    sep_SLRA = sep_SLRA.drop_duplicates()\n",
    "\n",
    "    #recalculate ratios\n",
    "    sep_SLRA['Total'] = sep_SLRA['feature_frequency'].groupby(sep_SLRA['sampleid']).transform('sum')\n",
    "    sep_SLRA['ratio'] = sep_SLRA['feature_frequency']/sep_SLRA['Total']\n",
    "    sep_SLRA['nASVs'] = sep_SLRA['feature_id'].groupby(sep_SLRA['sampleid']).transform('nunique')\n",
    "\n",
    "    sep_SLRA = sep_SLRA.drop_duplicates()\n",
    "\n",
    "    #make new df dependingg on plotting needs\n",
    "    sep_WO = separated[separated.size_code == \"W\"]\n",
    "    sep_WO = sep_WO.drop_duplicates()\n",
    "\n",
    "    sep_PO = separated[separated.size_code == \"P\"]\n",
    "    sep_PO = sep_PO.drop_duplicates()\n",
    "\n",
    "    sep_S = separated[separated.size_code == \"S\"]\n",
    "    sep_L = separated[separated.size_code == \"L\"]\n",
    "\n",
    "\n",
    "    sep_WO.reset_index(inplace=True, drop=True)\n",
    "    sep_SLRA.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    #newseparated = pd.concat([sep_SLRA.reset_index(drop=True), sep_WO.reset_index(drop=True)], axis=0).reset_index(drop=True)\n",
    "    newseparated = pd.concat([sep_SLRA, sep_WO, sep_PO, sep_L, sep_S], ignore_index=True)\n",
    "\n",
    "    newseparated['weekdepth'] = newseparated[\"weekn\"].astype(str) + newseparated[\"depth\"].astype(str)\n",
    "    newseparated['avg'] = newseparated['nASVs'].groupby(newseparated['weekdepth']).transform('mean')\n",
    "    newseparated['diff'] = newseparated['nASVs'] - newseparated['avg']\n",
    "\n",
    "    return newseparated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-2023.5",
   "language": "python",
   "name": "qiime2-2023.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
